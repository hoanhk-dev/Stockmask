{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98fa5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "import json\n",
    "import re\n",
    "import fitz  \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "class PDFProcessor:\n",
    "    def __init__(self, path_pdf, model_name: str = \"qwen2.5:1.5b\"):\n",
    "        self.path_pdf = path_pdf\n",
    "        self.model_name = model_name\n",
    "        self.SYSTEM_PROMPT  = '''\n",
    "        You read ONE page of a financial report.\n",
    "\n",
    "        Task:\n",
    "        List the main topics discussed on this page.\n",
    "\n",
    "        Rules:\n",
    "        - Topics must be short noun phrases.\n",
    "        - Only include topics clearly mentioned.\n",
    "        - No explanations.\n",
    "\n",
    "        Output:\n",
    "        Return ONLY a JSON array of strings.\n",
    "        '''\n",
    "\n",
    "    def extract_features_clean(self, text: str) -> list[str]:\n",
    "        return list(dict.fromkeys(\n",
    "            s.strip() for s in re.findall(r'\"([^\"]+)\"', text)\n",
    "        ))\n",
    "    \n",
    "    def extract_page_topics(\n",
    "        self,\n",
    "        page_content: str,\n",
    "        ) -> list[str]:\n",
    "\n",
    "        response = chat(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"\n",
    "                    Page content:\n",
    "                    \\\"\\\"\\\"\n",
    "                    {page_content}\n",
    "                    \\\"\\\"\\\"\n",
    "                    \"\"\"\n",
    "                },\n",
    "            ],\n",
    "            options={\n",
    "                \"temperature\": 0\n",
    "            }\n",
    "        )\n",
    "        raw = response.message.content.strip()\n",
    "        return raw\n",
    "\n",
    "    \n",
    "    def read_pdf_by_page(self):\n",
    "        doc = fitz.open(self.path_pdf)\n",
    "        results_list = []\n",
    "        result_text = \"\"\n",
    "\n",
    "        for page_index, page in enumerate(\n",
    "            tqdm(doc, desc=\"Reading PDF pages\", unit=\"page\"),\n",
    "            start=1\n",
    "        ):\n",
    "            text = page.get_text().strip()\n",
    "            ingredient = {\n",
    "                \"page\": page_index,\n",
    "                \"text\": self.extract_features_clean(\n",
    "                    self.extract_page_topics(text)\n",
    "                )\n",
    "            }\n",
    "            results_list.append(ingredient)\n",
    "            result_text += \" \" + str(ingredient)\n",
    "\n",
    "        return results_list, result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f09002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "class RetrievalWithPDFPage:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def run_gemini(\n",
    "        self,\n",
    "        user_prompt: str,\n",
    "        ) -> dict:\n",
    "        \"\"\"\n",
    "        Send text to Gemini and return parsed JSON output.\n",
    "        \"\"\"\n",
    "\n",
    "        model = genai.GenerativeModel(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "        response = model.generate_content(\n",
    "            user_prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0,\n",
    "                \"response_mime_type\": \"application/json\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raw = response.text.strip()\n",
    "        return raw\n",
    "\n",
    "    def retrieve_pages(self, list_indicators, context, descriptions):\n",
    "        user_prompt = f\"\"\"\n",
    "        You are given a list of indicators and a document structure.\n",
    "        Each page id describes the main information covered on that page.\n",
    "\n",
    "        Your task is to identify, for EACH indicator, the pages that are most likely to contain information relevant to that indicator.\n",
    "\n",
    "        It is normal and expected that the same page may be relevant to multiple indicators.\n",
    "        If an indicator includes a description or explanation, you MUST use that description as the primary semantic reference when identifying relevant pages, and prioritize pages that explicitly match the described concept over pages that only loosely relate by title.\n",
    "\n",
    "        Indicators:\n",
    "        {list_indicators}\n",
    "\n",
    "        Document structure:\n",
    "        {context}\n",
    "\n",
    "        Description:\n",
    "        {descriptions}\n",
    "\n",
    "        Output format (STRICT):\n",
    "        Return ONLY a single JSON object in the following structure:\n",
    "\n",
    "        {{\n",
    "        \"<indicator_1>\": {{\n",
    "            \"thinking\": \"<Why these pages are relevant to this indicator>\",\n",
    "            \"page_list\": [\"x\", \"y\"]\n",
    "        }},\n",
    "        \"<indicator_2>\": {{\n",
    "            \"thinking\": \"<Why these pages are relevant to this indicator>\",\n",
    "            \"page_list\": [\"a\"]\n",
    "        }}\n",
    "        }}\n",
    "\n",
    "        Do NOT output anything outside the JSON.\n",
    "        \"\"\"\n",
    "        return self.run_gemini(user_prompt=user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d728160",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pdf = \"data/kajima.co.jp/ir_e_all_2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e01b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading PDF pages: 100%|██████████| 168/168 [04:14<00:00,  1.52s/page]\n"
     ]
    }
   ],
   "source": [
    "model_ollama = \"qwen2.5:1.5b\"\n",
    "kajima_process = PDFProcessor(path_pdf, model_name=model_ollama)\n",
    "data = kajima_process.read_pdf_by_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d53e00b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'Shareholder Return Policy': {'thinking': \"This indicator refers to the company's approach to returning value to its shareholders. Relevant pages would discuss dividends, stock buybacks, equity, financial strategy, and overall stockholder returns. Pages 5, 36, 40, 41, 45, 91, 100, 101, 109, 115, and 137 directly mention these concepts, including 'Dividend', 'Stockholder Returns', 'Dividend Policy', 'Acquisition of Own Shares', 'ROE', 'financial_strategy', 'Stock Remuneration System', 'Performance-Linked Remuneration', 'Stockholder Dialogue', 'Basic Profit Allocation Policy', and 'Treasury Stock'.\", 'page_list': ['5', '36', '40', '41', '45', '91', '100', '101', '109', '115', '137']}, 'IR Event Frequency': {'thinking': \"This indicator relates to how often a company engages with investors through Investor Relations (IR) events. Pages that mention 'IR Activities', 'Financial Results Briefings', or 'Dialogue with Institutional Investors and Securities Analysts' are highly relevant. Pages 13 and 109 explicitly cover these aspects, indicating the company's disclosure framework and engagement with the investment community.\", 'page_list': ['13', '109']}, 'Owner-managed Company': {'thinking': \"The description for this indicator specifically highlights a company run by individuals (founder/family) holding more than 50% of the shares. Therefore, pages that discuss 'Shareholdings' or 'Stock Ownership Breakdown' are most relevant as they would provide information on the concentration of ownership. Pages 94 and 110 directly address these concepts, making them key to identifying an owner-managed company based on the given definition.\", 'page_list': ['94', '110']}}\n"
     ]
    }
   ],
   "source": [
    "retrieve = RetrievalWithPDFPage(model_name=\"gemini-2.5-flash\")\n",
    "list_indicator = [\"Shareholder Return Policy\", \"IR Event Frequency\", \"Owner-managed Company\"]\n",
    "context = data[1]\n",
    "descriptions = {\"Owner-managed Company\": \"A company run by one or a few individuals, including the founder or family members, and holding more than 50% of the shares -> Family company\"}\n",
    "\n",
    "result = retrieve.retrieve_pages(list_indicator, context, descriptions)\n",
    "isolation_json = json.loads(result)\n",
    "print(type(isolation_json))\n",
    "print(isolation_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f7c50",
   "metadata": {},
   "source": [
    "# Gen Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40821c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_ocr=False,      \n",
    "    do_table_structure=True,    \n",
    ")\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options,\n",
    "            backend=PyPdfiumDocumentBackend\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7c5f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenAnswerByPageContext:\n",
    "    def __init__(self, model_name:str, path_pdf:str):\n",
    "        self.model_name = model_name\n",
    "        self.path_pdf = path_pdf\n",
    "        \n",
    "    def run_gemini(self, user_prompt):\n",
    "        \n",
    "        model = genai.GenerativeModel(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "        response = model.generate_content(\n",
    "            user_prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0,\n",
    "            }\n",
    "        )\n",
    "        raw = response.text.strip()\n",
    "        return raw\n",
    "\n",
    "    def docling_parse_text(self, num_page):\n",
    "        result = doc_converter.convert(\n",
    "            source=self.path_pdf,\n",
    "            page_range=(num_page, num_page)\n",
    "        )\n",
    "        return result.document.export_to_markdown()\n",
    "\n",
    "    def gen_answers(self, isolation_json, descriptions):\n",
    "        answers = {}\n",
    "        for indicator, value in isolation_json.items():\n",
    "            \n",
    "            answers[indicator] = {}\n",
    "\n",
    "            print(\"Processing indicator:\", indicator)\n",
    "            context = \"\"\n",
    "            for page in value['page_list']:\n",
    "                context += self.docling_parse_text(int(page)) + \"\\n\"\n",
    "            \n",
    "            user_prompt = f\"\"\"\n",
    "            You are an expert financial analyst. \n",
    "            Based on the context provided, please extract information related to producted indicator.\n",
    "            If the indicator includes a description or explanation, you MUST treat it as a strict definition and use it as the primary semantic reference when extracting information from the context.\n",
    "\n",
    "            NOT: AUTO GENERATE ANYTHING THAT IS NOT IN THE CONTEXT.\n",
    "            \n",
    "            Indicator: {indicator}\n",
    "\n",
    "            Descriptions:\n",
    "            {descriptions}\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "            \"\"\"\n",
    "            answer = self.run_gemini(user_prompt)\n",
    "            \n",
    "            answers[indicator][\"answer\"] = answer\n",
    "            answers[indicator][\"page_list\"] = value['page_list']\n",
    "            answers[indicator][\"source\"] = self.path_pdf\n",
    "\n",
    "        return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02783d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indicator: Shareholder Return Policy\n",
      "Processing indicator: IR Event Frequency\n",
      "Processing indicator: Owner-managed Company\n"
     ]
    }
   ],
   "source": [
    "gen_answer_by_page_context = GenAnswerByPageContext(model_name=\"gemini-2.5-flash\", path_pdf=path_pdf)\n",
    "finall_answers = gen_answer_by_page_context.gen_answers(isolation_json, descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee360cd7",
   "metadata": {},
   "source": [
    "# Multi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c23c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoan.hk/Desktop/Works/Stock/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/9y/zttgshq9645cyp9y04vmgnjh0000gp/T/ipykernel_7807/1425994619.py:7: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import chat\n",
    "import json\n",
    "import re\n",
    "import fitz  \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e055d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29a9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFProcessor:\n",
    "    def __init__(self, model_name: str = \"qwen2.5:1.5b\"):\n",
    "        self.model_name = model_name\n",
    "        self.SYSTEM_PROMPT  = '''\n",
    "        You read ONE page of a financial report.\n",
    "\n",
    "        Task:\n",
    "        List the main topics discussed on this page.\n",
    "\n",
    "        Rules:\n",
    "        - Topics must be short noun phrases.\n",
    "        - Only include topics clearly mentioned.\n",
    "        - No explanations.\n",
    "\n",
    "        Output:\n",
    "        Return ONLY a JSON array of strings.\n",
    "        '''\n",
    "\n",
    "    def extract_features_clean(self, text: str) -> list[str]:\n",
    "        return list(dict.fromkeys(\n",
    "            s.strip() for s in re.findall(r'\"([^\"]+)\"', text)\n",
    "        ))\n",
    "    \n",
    "    def extract_page_topics(\n",
    "        self,\n",
    "        page_content: str,\n",
    "        ) -> list[str]:\n",
    "\n",
    "        response = chat(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"\n",
    "                    Page content:\n",
    "                    \\\"\\\"\\\"\n",
    "                    {page_content}\n",
    "                    \\\"\\\"\\\"\n",
    "                    \"\"\"\n",
    "                },\n",
    "            ],\n",
    "            options={\n",
    "                \"temperature\": 0\n",
    "            }\n",
    "        )\n",
    "        raw = response.message.content.strip()\n",
    "        return raw\n",
    "\n",
    "    \n",
    "    def read_pdf_by_page(self, path_pdf: str):\n",
    "        doc = fitz.open(path_pdf)\n",
    "        results_list = []\n",
    "        result_text = \"\"\n",
    "\n",
    "        for page_index, page in enumerate(\n",
    "            tqdm(doc, desc=\"Reading PDF pages\", unit=\"page\"),\n",
    "            start=1\n",
    "        ):\n",
    "            text = page.get_text().strip()\n",
    "            ingredient = {\n",
    "                \"page\": page_index,\n",
    "                \"text\": self.extract_features_clean(\n",
    "                    self.extract_page_topics(text)\n",
    "                )\n",
    "            }\n",
    "            results_list.append(ingredient)\n",
    "            result_text += \" \" + str(ingredient)\n",
    "\n",
    "        return results_list, result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0150d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFPageStructure:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def run_gemini(\n",
    "        self,\n",
    "        user_prompt: str,\n",
    "        ) -> dict:\n",
    "        \"\"\"\n",
    "        Send text to Gemini and return parsed JSON output.\n",
    "        \"\"\"\n",
    "\n",
    "        model = genai.GenerativeModel(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "        response = model.generate_content(\n",
    "            user_prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0,\n",
    "                \"response_mime_type\": \"application/json\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raw = response.text.strip()\n",
    "        return raw\n",
    "\n",
    "    def isolated_pages(self, list_indicators, context, descriptions):\n",
    "        user_prompt = f\"\"\"\n",
    "        You are given a list of indicators and a document structure.\n",
    "        Each page id describes the main information covered on that page.\n",
    "\n",
    "        Your task is to identify, for EACH indicator, the pages that are most likely to contain information relevant to that indicator.\n",
    "\n",
    "        It is normal and expected that the same page may be relevant to multiple indicators.\n",
    "        If an indicator includes a description or explanation, you MUST use that description as the primary semantic reference when identifying relevant pages, and prioritize pages that explicitly match the described concept over pages that only loosely relate by title.\n",
    "\n",
    "        Indicators:\n",
    "        {list_indicators}\n",
    "\n",
    "        Document structure:\n",
    "        {context}\n",
    "\n",
    "        Description:\n",
    "        {descriptions}\n",
    "\n",
    "        Output format (STRICT):\n",
    "        Return ONLY a single JSON object in the following structure:\n",
    "\n",
    "        {{\n",
    "        \"<indicator_1>\": {{\n",
    "            \"thinking\": \"<Why these pages are relevant to this indicator>\",\n",
    "            \"page_list\": [\"x\", \"y\"]\n",
    "        }},\n",
    "        \"<indicator_2>\": {{\n",
    "            \"thinking\": \"<Why these pages are relevant to this indicator>\",\n",
    "            \"page_list\": [\"a\"]\n",
    "        }}\n",
    "        }}\n",
    "\n",
    "        Do NOT output anything outside the JSON.\n",
    "        \"\"\"\n",
    "        return self.run_gemini(user_prompt=user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ff5f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_ocr=False,      \n",
    "    do_table_structure=True,    \n",
    ")\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options,\n",
    "            backend=PyPdfiumDocumentBackend\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenAnswerByPageContext:\n",
    "    def __init__(self, model_name:str):\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def run_gemini(self, user_prompt):\n",
    "        \n",
    "        model = genai.GenerativeModel(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "        response = model.generate_content(\n",
    "            user_prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0,\n",
    "            }\n",
    "        )\n",
    "        raw = response.text.strip()\n",
    "        return raw\n",
    "\n",
    "    def docling_parse_text(self, num_page, path_pdf):\n",
    "        result = doc_converter.convert(\n",
    "            source=path_pdf,\n",
    "            page_range=(num_page, num_page)\n",
    "        )\n",
    "        return result.document.export_to_markdown()\n",
    "\n",
    "    def gen_answers(self, isolation_json, descriptions, path_pdf):\n",
    "        \n",
    "        answers = {}\n",
    "\n",
    "        for indicator, value in isolation_json.items():\n",
    "            \n",
    "            answers[indicator] = {}\n",
    "\n",
    "            print(\"Processing indicator:\", indicator)\n",
    "            context = \"\"\n",
    "            for page in value['page_list']:\n",
    "                context += self.docling_parse_text(int(page), path_pdf) + \"\\n\"\n",
    "            \n",
    "            user_prompt = f\"\"\"\n",
    "            You are an expert financial analyst. \n",
    "            Based on the context provided, please extract information related to producted indicator.\n",
    "            If the indicator includes a description or explanation, you MUST treat it as a strict definition and use it as the primary semantic reference when extracting information from the context.\n",
    "            The context may not contain information relevant to the indicator. If the required information is NOT explicitly stated in the context, you MUST respond exactly with: \"HAVE NOT INFORMATION\".\n",
    "\n",
    "            NOT: AUTO GENERATE ANYTHING THAT IS NOT IN THE CONTEXT.\n",
    "            \n",
    "            Indicator: {indicator}\n",
    "\n",
    "            Descriptions:\n",
    "            {descriptions}\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "            \"\"\"\n",
    "            answer = self.run_gemini(user_prompt)\n",
    "            \n",
    "            answers[indicator][\"answer\"] = answer\n",
    "            answers[indicator][\"page_list\"] = value['page_list']\n",
    "            answers[indicator][\"source\"] = self.path_pdf\n",
    "\n",
    "        return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b777c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFRretrieval:\n",
    "    def __init__(self, mini_model, big_model):\n",
    "        self.mini_model = mini_model\n",
    "        self.big_model = big_model\n",
    "        self.pdf_processor = PDFProcessor(model_name = mini_model)\n",
    "        self.pdf_page_structure = PDFPageStructure(model_name = big_model)\n",
    "        self.gen_answer_by_page_context = GenAnswerByPageContext(model_name=big_model)\n",
    "\n",
    "    def run(self, file_paths, list_indicators, descriptions, type_report, target_site):\n",
    "        use_paths = file_paths[target_site][type_report]\n",
    "        TREES = {}\n",
    "        ISOLATED_DIC = {}\n",
    "\n",
    "        print(\"Start processing PDF pages - Gentree\")\n",
    "        time_gentree = 0\n",
    "\n",
    "        for path in use_paths:\n",
    "            start = time.time()\n",
    "            data = self.pdf_processor.read_pdf_by_page(path)\n",
    "            TREES[path] = data[1]\n",
    "            end = time.time()\n",
    "            time_value = end - start\n",
    "            time_gentree += time_value\n",
    "            \n",
    "            print(f\"Gentree: {path}\", round(time_value, 2), \"seconds\")\n",
    "            print()\n",
    "        print(\"--\"*20)\n",
    "        print(\"Total Gentree time:\", round(time_gentree, 2), \"seconds\")\n",
    "        print()\n",
    "\n",
    "        print(\"Start isolated\")\n",
    "        start = time.time()\n",
    "        \n",
    "        for indicator in list_indicators:\n",
    "            ISOLATED_DIC[indicator] = {}\n",
    "            \n",
    "        for path, context in TREES.items():\n",
    "            result = self.pdf_page_structure.isolated_pages(list_indicators, context, descriptions)\n",
    "            isolation_json = json.loads(result)\n",
    "            for key_indicator, value in isolation_json.items():\n",
    "                if path not in ISOLATED_DIC[key_indicator]:\n",
    "                    ISOLATED_DIC[key_indicator][path] = []\n",
    "                ISOLATED_DIC[key_indicator][path].extend(value['page_list'])\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"Total isolated pages: \", round(end - start, 2), \"seconds\")\n",
    "\n",
    "        return TREES, ISOLATED_DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c82920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing PDF pages - Gentree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading PDF pages: 100%|██████████| 1/1 [00:05<00:00,  5.47s/page]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gentree: data/kajima.co.jp/ir_e_p105-106.pdf 5.51 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading PDF pages: 100%|██████████| 1/1 [00:02<00:00,  2.89s/page]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gentree: data/kajima.co.jp/ir_e_p107-108.pdf 2.92 seconds\n",
      "\n",
      "----------------------------------------\n",
      "Total Gentree time: 8.43 seconds\n",
      "\n",
      "Start isolated\n",
      "Total isolated pages:  10.45 seconds\n"
     ]
    }
   ],
   "source": [
    "target_site = \"kajima.co.jp\"\n",
    "type_report = \"ir_report\"\n",
    "\n",
    "file_paths = {\n",
    "    \"kajima.co.jp\": \n",
    "        {\"ir_report\":\n",
    "            [\n",
    "                # \"data/kajima.co.jp/20250514-fs.pdf\",\n",
    "                # \"data/kajima.co.jp/ir_e_all_2.pdf\",\n",
    "                # \"data/kajima.co.jp/ir_e_p03-04.pdf\",\n",
    "                # \"data/kajima.co.jp/ir_e_p05-10.pdf\",\n",
    "                # \"data/kajima.co.jp/ir_e_p13-22.pdf\",\n",
    "                # \"data/kajima.co.jp/ir_e_p23-32.pdf\",\n",
    "                # \"data/kajima.co.jp/ir_e_p63-104.pdf\",\n",
    "                \"data/kajima.co.jp/ir_e_p105-106.pdf\",\n",
    "                \"data/kajima.co.jp/ir_e_p107-108.pdf\"\n",
    "            ]\n",
    "        }\n",
    "}\n",
    "\n",
    "list_indicators = [\n",
    "            \"Shareholder Return Policy\",\n",
    "            \"IR Event Frequency\",\n",
    "            \"Owner-managed Company\"\n",
    "        ]\n",
    "\n",
    "descriptions = {\n",
    "    \"Owner-managed Company\": \"A company run by one or a few individuals, including the founder or family members, and holding more than 50% of the shares -> Family company\"\n",
    "    }\n",
    "\n",
    "main = PDFRretrieval(mini_model=\"qwen2.5:1.5b\", big_model=\"gemini-2.5-flash\")\n",
    "trees, isolated_dic = main.run(file_paths= file_paths, list_indicators=list_indicators, descriptions=descriptions, type_report=type_report, target_site=target_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3911a49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shareholder Return Policy': {'data/kajima.co.jp/ir_e_p105-106.pdf': ['1'],\n",
       "  'data/kajima.co.jp/ir_e_p107-108.pdf': []},\n",
       " 'IR Event Frequency': {'data/kajima.co.jp/ir_e_p105-106.pdf': [],\n",
       "  'data/kajima.co.jp/ir_e_p107-108.pdf': []},\n",
       " 'Owner-managed Company': {'data/kajima.co.jp/ir_e_p105-106.pdf': [],\n",
       "  'data/kajima.co.jp/ir_e_p107-108.pdf': []}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolated_dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
